{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adb81e9",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "# Exemple : Concaténation et nettoyage des données OPM\n",
    "\n",
    "Ce notebook illustre deux étapes clés du pipeline :\n",
    "1. **Concaténation** de deux tables (2015 et 2024)\n",
    "2. **Nettoyage** d'une table de niveaux d'âge (`DTagelvl_Clean`)\n",
    "\n",
    "Les données proviennent de l'Office of Personnel Management (OPM, USA) et sont utilisées pour l'analyse de l'attrition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0582479",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da09e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pandas.api.types import CategoricalDtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d55a02",
   "metadata": {},
   "source": [
    "Concaténation des tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les chemins relatifs\n",
    "data_dir = Path(\"../data/raw\")\n",
    "\n",
    "# Charger les fichiers\n",
    "df_1 = pd.read_csv(data_dir / \"DTagy_2015.txt\")\n",
    "df_2 = pd.read_csv(data_dir / \"DTagy_2024.txt\")\n",
    "\n",
    "# Concaténer les deux DataFrames\n",
    "df_concat = pd.concat([df_1, df_2], ignore_index=True)\n",
    "\n",
    "# Supprimer les doublons\n",
    "df_concat.drop_duplicates(inplace=True)\n",
    "\n",
    "# Exporter vers CSV dans data/data/\n",
    "output_path = Path(\"../data/data/DTagy_Clean.csv\")\n",
    "df_concat.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier concaténé sauvegardé : {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5b275",
   "metadata": {},
   "source": [
    "Nettoyage de la table - DTagelvl_Clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier nettoyé\n",
    "df_0 = pd.read_csv(Path(\"../data/data/DTagelvl_Clean.csv\"))\n",
    "\n",
    "# Supprimer une ligne spécifique\n",
    "df_0.drop([11], inplace=True)\n",
    "\n",
    "# Modifier certaines valeurs\n",
    "df_0.replace(\n",
    "    {\"Less than 20\": \"<20\",\n",
    "     \"65 or more\": \">=65\"}, \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Définir l'ordre des catégories d'âge\n",
    "age_order = CategoricalDtype(\n",
    "    categories=[\"<20\", \"20-24\", \"25-29\", \"30-34\", \"35-39\", \"40-44\", \n",
    "                \"45-49\", \"50-54\", \"55-59\", \"60-64\", \">=65\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "df_0[\"AGELVLT\"] = df_0[\"AGELVLT\"].astype(age_order)\n",
    "\n",
    "# Extraire la borne supérieure de l'âge\n",
    "def extract_upper_bound(age_category):\n",
    "    if age_category == \"Unspecified\":\n",
    "        return np.nan \n",
    "    elif age_category == \"<20\":\n",
    "        return 20 \n",
    "    elif age_category == \">=65\":\n",
    "        return 65  \n",
    "    else:\n",
    "        return int(age_category.split('-')[-1]) \n",
    "\n",
    "df_0[\"AGELVLT_Age\"] = df_0[\"AGELVLT\"].apply(extract_upper_bound).astype(\"Int64\")\n",
    "\n",
    "# Renommer la table finale\n",
    "DTagelvl_net = df_0\n",
    "\n",
    "# Exporter vers CSV\n",
    "DTagelvl_net.to_csv(Path(\"../data/data/DTagelvl_net.csv\"), index=False)\n",
    "\n",
    "print(\"Table nettoyée exportée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c61c8a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook démontre :\n",
    "- La fusion de deux tables brutes en un dataset unique\n",
    "- Le nettoyage et la transformation d'une table de niveaux d'âge\n",
    "- L'export des fichiers prêts pour analyse\n",
    "\n",
    "Ces étapes font partie du pipeline complet d'analyse de l'attrition.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
